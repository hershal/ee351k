\documentclass[12pt]{article}
\title{EE351K Homework 7}
\author{Hershal Bhave (hb6279)}
\date{Due October 23, 2014}

\usepackage{multicol}
\usepackage[in]{fullpage}
\usepackage{xcolor}
\usepackage{rotating}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{cleveref}
\usepackage{graphics}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage[nosolutionfiles]{answers}
\usepackage[acronym]{glossaries}

\newenvironment{Ex}{\textbf{Problem}\vspace{.75em}\\}{}
\Newassociation{solution}{Soln}{Answers}
\pagebreak[3]
\newcommand{\Opentesthook}[2]{\Writetofile{#1}{\protect\section{#1: #2}}}
\renewcommand{\Solnlabel}[1]{\textbf{Solution}\quad}

\newcommand{\dd}[1]{\:\mathrm{d}{#1}}
\newcommand{\ddt}[1]{\frac{\dd{}}{\dd{#1}}}
\newcommand{\dddt}[1]{\frac{\dd{}^2}{\dd{#1}^2}}

\begin{document}
\maketitle
\begin{enumerate}
\item
  \begin{Ex}
    $X$ and $Y$ are two independent exponential random variables with
    parameters $\lambda_1$ and $\lambda_2$ respectively. Let $Z$ be a
    random variable defined as $Z = \text{max}[X,Y]$; find the
    distribution of $Z$.
    \begin{solution} \hfill \vspace{.75em} \\
      \begin{equation}
        \label{eq:1-sol}
        \begin{aligned}
          F_Z(z) &= P(\text{max}[X,Y] \le z) \\
          &= P(X \le z, Y \le z) \\
          &= P(X\le z)P(Y\le z) \\
          &= (1-e^{-\lambda_1 z})(1-e^{-\lambda_2 z}) \\
          &= 1-e^{-\lambda_1 z} - e^{-\lambda_2 z} + e^{-(\lambda_1 +
            \lambda_2) z} \\
          &= (1 - e^{-\lambda_1 z}) + (1 - e^{-\lambda_2 z})+ (-1 +
          e^{-(\lambda_1 + \lambda_2) z}) \\
          &= (1-e^{-\lambda_1 z}) + (1-e^{-\lambda_2 z}) -
          (1-e^{-(\lambda_1 + \lambda_2) z}) \\
          \implies Z &\sim \text{exp}(\lambda_1) + \text{exp}(\lambda_2)
          - \text{exp}(\lambda_1 + \lambda_2) \\
          \text{Or }\implies Z &\sim
          \text{exp}(\lambda_1)\text{exp}(\lambda_2) \\
        \end{aligned}
      \end{equation}
    \end{solution}
  \end{Ex}
\pagebreak[4]
\item
  \begin{Ex}
    Let $X$ be a continuous random variable with CDF $F_X(x)$ which is
    strictly increasing and $Y$ be a derived random variable defined
    as $Y = F_X(X)$. Find the distribution of $Y$.  Note that CDF of
    any given random variable is just another function.
    \begin{solution} \hfill \vspace{.75em} \\
      \begin{equation}
        \label{eq:2-presol}
        \begin{aligned}
          F_Y(y) &= P(Y\le y) = P(F_X(x)\le y) \\
          &= \int_{\{x|F_X(X) \le y\}}f_X(x) \dd{x} \\
        \end{aligned}
      \end{equation}
      The distribution is then the derivative of the CDF of $Y$.
      \begin{equation}
        \label{eq:2-sol}
        % \implies f_Y(y) = \frac{d}{\dd{y}}\int_{\{x|F_X(X) \le
        %   y\}}f_X(x) \dd{x}
        \implies f_Y(y) = f_X(h(y)) \left|\frac{\dd{h}}{\dd{y}}(y)\right|
      \end{equation}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    Let $X$ be a discrete random variable with PMF $p_X$ and let $Y$
    be a continuous random variable, independent from $X$, with PDF
    $f_Y$. Derive a formula for the PDF of the random variable $X+Y$.
    \begin{solution} \hfill \vspace{.75em} \\
      \begin{equation}
        \label{eq:3-presol}
        \begin{aligned}
          F_Z(z) &= P(Z \le z) = P(X+Y \le z) \\
          &= \sum_x P(X+Y\le z | X=x)p_X(x) \\
          &= \sum_x P(Y \le z-x | X=x)p_X(x) \\
          &= \sum_x P(Y \le z-x)p_X(x) \\
          &= \sum_x F_Y(z-x)p_X(x) \\
        \end{aligned}
      \end{equation}
      Then the distribution of $Z$ is the derivative of its CDF
      \begin{equation}
        \label{eq:3-sol}
        \begin{aligned}
          f_Z(z) &= \frac{d}{\dd{z}}F_Z(z) \\
          &= \frac{d}{\dd{z}}\sum_{x}F_Y(z-x)p_X(x) \\
          &= \sum_{x}\frac{d}{\dd{z}}F_Y(z-x)p_X(x) \\
          \implies f_Z(z) &= \sum_{x}f_Y(z-x)p_X(x) \\
        \end{aligned}
      \end{equation}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    A random variable $X$ has mean 0 and variance 1. A random variable
    $Y$ has mean 1 and variance 2, and $X$ and $Y$ are
    independent. Suppose random variables $U$ and $V$ are given by
    $U=X+2Y$, $V = X−Y$. What is the covariance $\text{Cov}(U,V)$?
    What is the correlation coefficient $\rho_{U,V}$? Can $U$ and $V$
    be independent?
    \begin{solution} \hfill \vspace{.75em} \\
      The covariance formula is
      \begin{equation}
        \label{eq:4-cov}
        \text{Cov}(U,V) = E[UV] - E[U]E[V]
      \end{equation}
      We must first obtain each component of the covariance formula:
      \begin{equation}
        \label{eq:4-e-u}
        \begin{aligned}
          E[U] &= E[X+2Y] \\
          &= E[X] + 2E[Y] \\
          \implies E[U] &= 2 \\
        \end{aligned}
      \end{equation}
      and
      \begin{equation}
        \label{eq:4-e-v}
        \begin{aligned}
          E[V] &= E[X]E[Y] \\
          &= (0)(1) \\
          \implies E[V] &= 0 \\
        \end{aligned}
      \end{equation}
      and
      \begin{equation}
        \label{eq:4-e-uv}
        \begin{aligned}
          E[UV] &= (X+2Y)(XY) \\
          &= X^2+Y + 2XY^2 \\
          \implies E[UV] &= 0 \\
        \end{aligned}
      \end{equation}
      Using the individual components found in
      \cref{eq:4-e-u,eq:4-e-v,eq:4-e-uv}, we can find the covariance
      using \cref{eq:4-cov}
      \begin{equation}
        \label{eq:4-cov-plugged}
        \begin{aligned}
          \text{Cov}(U,V) &= E[UV] - E[U]E[V] \\
          &= 0 - (2)(0) \\
          \implies \text{Cov}(U,V) &= 0 \\
        \end{aligned}
      \end{equation}
      The correlation coefficient is
      \begin{equation}
        \label{eq:4-c-coef}
        \rho(X,Y) \frac{\text{Cov}(X,Y)}{\sqrt{\text{Var}(X)\text{Var}(Y)}}
      \end{equation}
      Since $\text{Cov}(U,V)$ is zero,
      \begin{equation}
        \label{eq:4-coef-sol}
        \implies \rho(U,V) = 0
      \end{equation}
      This does not guarantee that $U$ and $V$ are independent, though
      they can be.
      \\\\ {\color{red} \huge CHECK}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    Consider $n$ independent tosses of a $k$-sided fair die. Let $X_i$
    be the number of tosses that result in outcome $i$. Find
    $\text{Cov}(X_1 , X_2)$ of $X_1$ and $X_2$.

    Hint: Define a Bernoulli random variable $A_t$ that is equal to 1
    if and only if the $t$th toss resulted in 1. Note that $X_1 =
    A_1+A_2+\ldots+A_n$.
    \begin{solution} \hfill \vspace{.75em} \\
      Intuitively, the $\text{Cov}(X_1 , X_2)$ would be 0 since the
      random variables $X_1$ and $X_2$ are independent because each
      toss is independent of the other and each outcome has an equally
      likely, equally independent outcome. Since the covariance
      between independent variables is 0, then we can assume that
      $\text{Cov}(X_1 , X_2) = 0$.
      \\\\ {\color{red} \huge CHECK}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    Let c be an integer where $c > 1$. We are given $c$ independent
    random variables, denoted $X_1, \ldots ,X_c$ and $c$ positively
    correlated random variables, denoted by $Y_1, \ldots, Y_c$ such
    that correlation between any two random variables $Y_i$ and $Y_j$
    is a constant value $\rho < 1$. All the given random variables
    have same mean and variance.
    \begin{enumerate}
    \item Which of the following has a lower variance?
      \begin{equation}
        \label{eq:6-question-eq-0}
        \text{Var}(X_1 + X_2 + \cdots + X_c)
      \end{equation}
      \begin{equation}
        \label{eq:6-question-eq-1}
        \text{Var}(Y_1 + Y_2 + \cdots + Y_c)
      \end{equation}
      \begin{equation}
        \label{eq:6-question-eq-2}
        \text{Var}(cX_1)
      \end{equation}
      Compute each of these to relate them.
    \item Suppose each random variable denotes an investment in a
      given stock. Consider the following cases, investing $c$ times
      in a single stock, investing in $c$ independent stocks and
      investing in $c$ positively correlated stocks. Which investement
      is invovled with less risk? Explain your answer using the result
      to the previous question.
    \end{enumerate}
    \begin{solution} \hfill \vspace{.75em} \\
      In general,
      \begin{equation}
        \label{eq:6-variance-sum}
        \text{Var}\left(\sum_{i=1}^{n}X_i\right) =
        \left(\sum_{i=1}^{n}\text{Var}(X_i)\right) +
        \left(\sum_{\{(i,j)|i\not= j\}}^{n}\text{Cov}(X_i, X_j)\right)
      \end{equation}
      So then since $X_1, \ldots, X_c$ are all independent, their
      covariance is zero, thus eliminating the $\text{Cov}(X_i,
      X_{i+1})$ element from the variance. If $E[X_1] < 1$, then
      \cref{eq:6-question-eq-2} is the smallest value, followed by
      \cref{eq:6-question-eq-0}, followed by
      \cref{eq:6-question-eq-1}. Otherwise \cref{eq:6-question-eq-0}
      is the smallest, followed by \cref{eq:6-question-eq-1}, followed
      by \cref{eq:6-question-eq-2}.
      \\\\ {\color{red} \huge CHECK}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    Let $X$ be a random variable uniformly distributed between −0.5
    and 0.5 and $q$ be a uniform quantizer function with resolution of
    $n$ bits. If $n = 2$, the quantizer function is shown below.

    {\color{red} \huge SHOW QUANTIZER FUNCTION}

    Let $Y = q(X)$ be a derived random variable. Random variable $Y$
    takes four values for $n = 2$, where each value will be associated
    with two bits. SNR is used as a measure of quality for the
    quantizer and is defined as $$\text{SNR} = \sigma_X^2
    E[(X−q(X))^2]$$ Find SNR for $n=2$. SNR in db is defined as
    $\text{SNR}_{\text{db}} = 10\log 10\;\text{SNR}$ .What happens to
    $\text{SNR}_{\text{db}}$ as number of bits, $n$ increases?

    \begin{solution} \hfill \vspace{.75em} \\
      {\color{red} \huge TODO}
    \end{solution}
  \end{Ex}

\end{enumerate}
\end{document}
