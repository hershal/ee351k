\documentclass[12pt]{article}
\title{EE351K Homework 10}
\author{Hershal Bhave (hb6279)}
\date{Due November 20, 2014}

\usepackage{multicol}
\usepackage{float}
\usepackage[in]{fullpage}
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage{tabularx}
\usepackage{rotating}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{cleveref}
\usepackage{graphics}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage[nosolutionfiles]{answers}
\usepackage[acronym]{glossaries}

\newenvironment{Ex}{\textbf{Problem}\vspace{.75em}\\}{}
\Newassociation{solution}{Soln}{Answers}
\pagebreak[3]
\newcommand{\Opentesthook}[2]{\Writetofile{#1}{\protect\section{#1: #2}}}
\renewcommand{\Solnlabel}[1]{\textbf{Solution}\quad}

\newcommand{\dd}[1]{\:\mathrm{d}{#1}}
\newcommand{\ddt}[1]{\frac{\dd{}}{\dd{#1}}}
\newcommand{\dddt}[1]{\frac{\dd{}^2}{\dd{#1}^2}}

\DeclareMathOperator*{\argmax}{arg\,max}

\definecolor{silver}{rgb}{0.95,0.95,0.95}

\begin{document}
\maketitle
\begin{enumerate}
\item
  \begin{Ex}
    At a computer disk drive factory, inspectors randomly pick a
    product from production lines to detect a failure. If the
    production lines are normal, this failure rate $q_0 =
    10^{-4}$. However occasionally some problems occur in the lines,
    in which case the rate goes up to $q_1 = 10^{-1}$. Let $H_i$
    denote the hypothesis that the failure rate is $q_i$.

    Every morning, an inspector chooses drives at random from the
    previous day’s production and tests them. If a failure occurs too
    soon, the company stops production and checks the critical part of
    the process. Production line problems occur at random once every
    10 days, so that $P(H_1) = 0.1 = 1 - P(H_0)$.

    \begin{enumerate}
    \item Based on $N$, the number of drives tested up to and
      including the first failure, design a MAP test.
    \item Calculate the probability of ``false alarm'' and the
      probability of ``missed detection''.
    \item Based on this, calculate the probability of detection error
      $P_e$.
    \end{enumerate}
    \begin{solution} \hfill
      {\huge \color{red} TODO}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    Suppose that $X_1,\ldots,X_n$ form a random sample from a uniform
    distribution on the interval $(0,\theta)$, where of the parameter
    $\theta > 0$ but is unknown. Please find MLE of $\theta$.
    \begin{solution} \hfill
      {\huge \color{red} TODO}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    Let $X$ be a random variable uniform over the interval $[2,
    12]$. Suppose we observe $X$ with some random error $N$ which is
    uniformly distributed over interval $[0,1]$. i.e., $Y =X+N$
    \begin{enumerate}
    \item Find the Least mean square estimate of X based on the
      observation $Y = y$.
    \item Find the mean square error.
    \end{enumerate}
    \begin{solution} \hfill
      {\huge \color{red} TODO}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    Romeo and Juliet start dating, but Juliet will be late on any date
    by a random amount X, uniformly distributed over the interval $[0,
    \theta]$. The parameter $\theta$ is unknown and is modeled as the
    value of a random variable $\Theta$, uniformly distributed between
    zero and one hour.
    \begin{enumerate}
    \item Assuming that Juliet was late by an amount $x$ on their
      first date, how should Romeo use this information to update the
      distribution of $\Theta$?
    \item Find the MAP estimate of $\Theta$ based on the observation
      $X = x$.
    \item Find the Least Mean Square estimate of $\Theta$ based on the
      observation $X = x$.
    \item Derive the Linear Least Mean Square estimator of $\Theta$
      based on $X$.
    \end{enumerate}
    \begin{solution} \hfill
      \begin{enumerate}
      \item We were given that $X\sim\text{Uniform}(0,\theta)$ and
        $\Theta\sim\text{Uniform}(0,1)$.

        Since $\Theta$ is uniform, we can define the PDF of $\Theta$
        \begin{equation}
          \label{eq:4a-pdf-theta}
          f_\Theta(\theta)=\left\{
            \begin{aligned}
              & 1 &&\quad 0\le\theta\le1 \\
              & 0 &&\quad \text{otherwise} \\
            \end{aligned}\right.
        \end{equation}
        and the conditional PDF of $X$ given $\Theta$
        \begin{equation}
          \label{eq:4a-pdf-x-given-theta}
          f_\Theta(\theta)=\left\{
            \begin{aligned}
              & \frac{1}{\theta} &&\quad 0\le x \le\theta \\
              & 0 &&\quad \text{otherwise} \\
            \end{aligned}\right.
        \end{equation}

        So now we must obtain the posterior PDF. We can use Bayes'
        Rule.

        \begin{mdframed}[backgroundcolor=silver]
          \begin{description}
          \item[Bayes' Rule] \hfill \\
            $$f_{\Theta|X}(\theta|x) =
            \frac{f_{\Theta}(\theta)f_{X|\Theta}(x|\theta)} {\int
              f_{\Theta}(\theta^{\prime})f_{X|\Theta}(x|\theta^{\prime})
              \dd{\theta^{\prime}}}$$
            Where $f_{\Theta}$ is the prior distribution and
            $f_{X|\Theta}$ is the model of the observation vector
            $X$. After observing the value $x$ of $X$, we form the
            posterior distribution of $\Theta$, using Bayes' Rule.
          \end{description}
        \end{mdframed}

        \begin{equation}
          \label{eq:4a-presol}
          \begin{aligned}
            f_{X|\Theta} &=
            \frac{f_{\Theta}(\theta)f_{X|\Theta}(x|\theta)} {\int
              f_{\Theta}(\theta^{\prime})f_{X|\Theta}(x|\theta^{\prime})
              \dd{\theta^{\prime}}} \\
            &= \frac{(1)(\frac{1}{\theta})}{\int_x^1
                (1)(\frac{1}{\theta}) \dd{\theta^{\prime}}} \\
            &= \frac{1}{\theta}[\ln(\theta^{\prime})]_x^1 \\
            &= \frac{1}{\theta}(\ln(1) - \ln(x)) \\
            &= \frac{1}{\theta}(-\ln(x)) \\
            \implies f_{X|\Theta}&= \frac{1}{\theta\ln(x)} \\
          \end{aligned}
        \end{equation}
        For precision,
        \begin{equation}
          \label{eq:4a-sol}
            \implies f_{X|\Theta} = \left\{
              \begin{aligned}
                & \frac{1}{\theta|\ln(x)|}
                &&\quad 0\le x\le\theta\le 1 \\
                & 0 &&\quad\text{otherwise} \\
              \end{aligned} \right.
        \end{equation}
      \item We must use the MAP estimator.
        \begin{mdframed}[backgroundcolor=silver]
          \begin{description}
          \item[MAP Estimator] \hfill \\
            $$\hat{\theta} = \argmax_{\theta}
            f_{\Theta|X}(\theta|x)$$

            We select a value of $theta$, denoted $\hat{\theta}$,
            which maximizes the posterior distribution
            $f_{\Theta|X}(\theta|x)$.
          \end{description}
        \end{mdframed}
        In our case, maximizing $f_{\Theta|X}(\theta|x)$ requires us
        to select the lowest value possible for $\hat{\theta}$ since a
        lower value in the denominator of a fraction promotes larger
        values when written in decimal. The lowest possible value we
        may choose for $\hat{\theta}$ in order to maximize
        $f_{\Theta|X}(\theta|x)$ is $\hat{\theta}=x$.
      \item We must use the LMS estimator.
        \begin{mdframed}[backgroundcolor=silver]
          \begin{description}
          \item[LMS Estimator] \hfill \\
            $$\hat{\theta} = E[\Theta|X=x]$$
          \end{description}
        \end{mdframed}
        Utilizing the LMS estimator simply requires some calculation.
        \begin{equation}
          \label{eq:4c-sol}
          \begin{aligned}
            \hat{\theta} &= E[\Theta|X=x] \\
            &= \int_x^1 \theta \frac{1}{\theta|\ln x|} \dd{\theta} \\
            &= \int_x^1 \frac{1}{|\ln x|} \dd{\theta} \\
            &= \frac{1}{|\ln x|} [\theta]_x^1 \\
            &= \frac{1}{|\ln x|} (1-x) \\
            \implies \hat{\theta} &= \frac{1-x}{|\ln x|} \\
          \end{aligned}
        \end{equation}
      \item  We must use the LLMS estimator.
        \begin{mdframed}[backgroundcolor=silver]
          \begin{description}
          \item[LLMS Estimator] \hfill \\
            $$\hat{\theta} = E[\Theta]+
            \frac{\text{Cov}(\Theta,X)}{\text{Var}(X)}
            (X-E[X])$$
            or alternatively
            $$\hat{\theta} = E[\Theta]+
            \rho\frac{\sigma_{\Theta}}{\sigma_{X}}(X-E[X])$$
            where
            $$\rho =
            \frac{\text{Cov}(\Theta,X)}{\sigma_{\Theta}\sigma_{X}}$$
          \end{description}
        \end{mdframed}

      \end{enumerate}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    Of 500 voters asked whether they are going to vote republican, 260
    said yes.
    \begin{enumerate}
    \item Find a 95\% confidence interval of the probability $p$ that
      the vote for a certain office will be for the republican
      candidate.
    \item Suppose that 475 of 500 voters said they will vote
      Democrat. Repeat part (a).
    \end{enumerate}
    \begin{solution} \hfill
      {\huge \color{red} TODO}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    Professor Hoogle always wonders what would be a fair grade for
    students that take his course. Even if you are an outstanding
    student, you usually don’t do well on every assignment. With many
    years of teaching experience, he concludes that the
    ``fluctuations'' of a student’s performance over the assignments,
    i.e., the standard deviation of points a student gets on
    assignments, is fixed to 5 points. This semester he decides to
    give grades according to the mean points of assignments. However
    this would be a sample mean and he wants to have a confidence
    interval less than 6 points with probability 0.95 for the true
    performance of a student, i.e., the true mean of assignment
    points. What is the minimum number of assignments he should give?
    \begin{solution} \hfill
      {\huge \color{red} TODO}
    \end{solution}
  \end{Ex}
\end{enumerate}
\end{document}
