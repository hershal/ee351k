\documentclass[12pt]{article}
\title{EE351K Homework 8}
\author{Hershal Bhave (hb6279)}
\date{Due October 30, 2014}

\usepackage{multicol}
\usepackage[in]{fullpage}
\usepackage{xcolor}
\usepackage{tabularx}
\usepackage{rotating}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{cleveref}
\usepackage{graphics}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage[nosolutionfiles]{answers}
\usepackage[acronym]{glossaries}

\newenvironment{Ex}{\textbf{Problem}\vspace{.75em}\\}{}
\Newassociation{solution}{Soln}{Answers}
\pagebreak[3]
\newcommand{\Opentesthook}[2]{\Writetofile{#1}{\protect\section{#1: #2}}}
\renewcommand{\Solnlabel}[1]{\textbf{Solution}\quad}

\newcommand{\dd}[1]{\:\mathrm{d}{#1}}
\newcommand{\ddt}[1]{\frac{\dd{}}{\dd{#1}}}
\newcommand{\dddt}[1]{\frac{\dd{}^2}{\dd{#1}^2}}

\begin{document}
\maketitle
\begin{enumerate}
\item
  \begin{Ex}
    Suppose the joint probability density function of two random
    variables $X$ and $Y$ is given by
    \begin{equation}
      \label{eq:1-question}
      f_{X,Y}(x,y) = \left\{
        \begin{aligned}
          & 2 &&\quad 0\le y \le x \le 1 \\
          & 0 &&\quad \text{otherwise} \\
        \end{aligned} \right.
    \end{equation}
    Find $E[X|Y]$ and $\text{Var}[X|Y]$. Recall that $E[X|Y]$ is a
    random variable, which is a fuction of $Y$.
    \begin{solution}
      First we must find the conditional PDF
      \begin{equation}
        \label{eq:1-conditional-pdf-def}
          f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}
      \end{equation}
      Where the marginal $f_Y(y)$ is
      \begin{equation}
        \label{eq:1-y-pdf}
        \begin{aligned}
          f_Y(y) &= \int_y^1 2\dd{x} \\
          &= [2x]_y^1 \\
          \implies f_Y(y) &= 2(1-y) \\
        \end{aligned}
      \end{equation}
      We can use the marginal obtained from \cref{eq:1-y-pdf} and insert
      it into the conditional pdf described into
      \cref{eq:1-conditional-pdf-def}
      \begin{equation}
        \label{eq:1-pdf-plugged}
        \begin{aligned}
          f_{X|Y}(x|y) &= \frac{f_{X,Y}(x,y)}{f_Y(y)} \\
          &= \frac{2}{2(1-y)} \\
          \implies f_{X|Y}(x|y) &= \frac{1}{1-y} \\
        \end{aligned}
      \end{equation}
      Now computing the conditional expectation:
      \begin{equation}
        \label{eq:1-conditional-expectation}
        \begin{aligned}
          E[X|Y] &= \int_y^1 x f_{X|Y}(x|y) \dd{x} \\
          &= \frac{1}{1-y} \int_y^1 x \dd{x} \\
          &= \frac{1}{1-y} \left[\frac{x^2}{2}\right]_y^1 \\
          &= \frac{1}{2(1-y)} (1-y^2) \\
          &= \frac{1}{2(1-y)} (1-y)(1+y) \\
          &= \frac{1+y}{2} \\
          \implies E[X|Y] &= \frac{1+Y}{2} \\
        \end{aligned}
      \end{equation}
      {\color{red} \huge FIND CONDITIONAL VARIANCE}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    Let $X$, $Y$, and $Z$ be jointly discrete random variables. Show
    that
    \begin{equation}
      \label{eq:2-question}
      E[Z] = E[E[Z|X,Y]]
    \end{equation}
    Recall that
    \begin{equation}
      \label{eq:2-recall}
      E[Z|X=x,Y=y] = \sum_z zP_{Z|X,Y}(z|x,y)
    \end{equation}
    Let
    \begin{equation}
      \label{eq:2-let}
      \gamma(x,y)=E[Z|X=x,Y=y]
    \end{equation}
    Then
    \begin{equation}
      \label{eq:2-then}
      E[Z|X,Y] = \gamma(X,Y)
    \end{equation}
    \begin{solution} \hfill
      \begin{equation}
        \label{eq:2-first-sum}
        \begin{aligned}
          E[E[Z|X,Y]] &= E[\gamma(X,Y)] \\
          &= \sum_{x,y} \gamma(X,Y)p_{X,Y}(x,y) \\
          &= \sum_{x,y} E[Z|X,Y] p_{X,Y}(x,y) \\
          &= \sum_{x,y} p_{X,Y}(x,y) \sum_{z} z p_{Z|X,Y}(z|x,y) \\
          &= \sum_{z} z \sum_{x,y} p_{X,Y}(x,y) p_{Z|X,Y}(z|x,y) \\
          &= \sum_{z} z \sum_{x,y} p_{X,Y,Z}(x,y,z) \\
          &= \sum_{z} z p_Z(z) \\
          \implies E[E[Z|X,Y]] &= E[Z] \\
        \end{aligned}
      \end{equation}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    You roll a fair six-sided die, and then you flip a fair coin the
    number of times shown by the die. Find the mean and the variance
    of the number of heads obtained.
    \begin{solution} \hfill \vspace{.75em} \\
      First, let's define a few variables:
      \begin{equation}
        \label{eq:3-decls}
        \begin{aligned}
          D &= \text{ the dice roll outcome, i.e. the number of rolls} \\
          H &= \text{ number of coin flips resulting in heads} \\
        \end{aligned}
      \end{equation}
      The number of heads obtained is the conditional expected value
      $E[H|D]$. When $D=d$, then the distribution of $H$ is binomial
      with $p=0.5$ such that $E[H|D]=0.5D$ and $\text{Var}(H|D) =
      0.25D$. We want to obtain the mean and variance of these
      distributions, respectively
      \\
      \begin{tabularx}{.95\textwidth}{XX}
        \begin{equation}
          \label{eq:3-e}
          \begin{aligned}
            E[E[H|D]] &= E[H] \\
            &= 0.5E[D] \\
            &= 0.5(3.5) \\
            \implies E[E[H|D]] &= 1.75 \\
          \end{aligned}
        \end{equation} &
        \begin{equation}
          \label{eq:3-var}
          \begin{aligned}
            \text{Var}(H|D) &= \text{Var}(H) \\
            &= 0.25(E[D^2] - E[D]^2) \\
            &= 0.25(91/6 - 3.5^2) \\
            \text{Var}(H) &= 0.7292 \\
          \end{aligned}
        \end{equation}
      \end{tabularx}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    A certain Sport club has N members, where N is a random variable
    with PMF
    \begin{equation}
      \label{eq:4-question-0}
      p_N(n) = p^{n-1}(1-p) \quad n=1,2,\ldots
    \end{equation}
    On the second Tuesday night of every month, the club holds a
    meeting. Each member attends the meeting with probability $q$,
    independently of all the other members. If a member $i$ attends
    the meeting, then he/she brings an amount of money, $M_i$, which is a
    continuous random variable with PDF
    \begin{equation}
      \label{eq:4-question-1}
      f_{M_{i}}(m) = \lambda e^{-\lambda m}\quad m\ge0
    \end{equation}
%    $N$, $M_i$, and whether each member attends are all
%    independent.
    Determine:
    \begin{enumerate}
    \item The expectation and variance of the number of members
      showing up to the meeting.
    \item The expectation and variance for the total amount of money
      brought to the meeting.
    \end{enumerate}
    \begin{solution} \hfill
      \begin{enumerate}
      \item {\color{red} \huge TODO}
      \item {\color{red} \huge TODO}
      \end{enumerate}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    A random variable $X \sim N(0,1)$ and $Y \sim N(1,2)$ and $X$ and
    $Y$ are independent. Suppose random variables $U$ and $V$ are
    given by $U=X+Y$, $V=X+\alpha Y$ for some $\alpha$.
    \begin{enumerate}
    \item What is the joint distribution of $U,V$ in terms of
      $\alpha$?
    \item Find $\alpha$ (if it exists) such that $U$ and $V$ be
      independent.
    \item Find the conditional distribution $f_{U|V}(u|V = 5)$.
    \end{enumerate}
    \begin{solution} \hfill
      \begin{enumerate}
      \item {\color{red} \huge TODO}
      \item {\color{red} \huge TODO}
      \item {\color{red} \huge TODO}
      \end{enumerate}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    Suppose $X$ is a Poisson variable with mean 10. Use Chebyshev's
    Inequality to give a lower bound of $P(5 < X < 15)$.
    \begin{solution} \hfill
      \\\\ {\color{red} \huge TODO}
    \end{solution}
  \end{Ex}
\item
  \begin{Ex}
    There are 10,000 light bulbs on an LED panel. Suppose that the
    lifetime of each light bulb is exponentially distributed with mean
    50 days, and assume that the light bulbs work independently of one
    another. Suppose that we turn all the light bulbs on and keep them
    on until they burn out. Use Markov's Inequality to give an upper
    bound of the probability that at least 8000 light bulbs are still
    on at the end of the 60th day after we turn them on.
    \begin{solution} \hfill
      \\\\ {\color{red} \huge TODO}
    \end{solution}
  \end{Ex}

\end{enumerate}
\end{document}
