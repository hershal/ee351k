\documentclass[8pt]{article}

\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{tabularx}
\usepackage{mathabx}
\usepackage{enumitem}
\usepackage{caption}
\usepackage{multicol}
\usepackage{sectsty}
\usepackage{extsizes}
\usepackage{fancyhdr}
\usepackage{enumerate}
\usepackage[margin=1.5cm]{geometry}
\usepackage{multirow}

\pagestyle{fancyplain}

% Try very hard not to break relational and binary operators (equations)
\relpenalty=9999
\binoppenalty=9999

\newcommand{\dd}[1]{\mathrm{d}{#1}}
\newcommand{\ddt}[1]{\frac{\dd{}}{\dd{#1}}}
\newcommand{\dddt}[1]{\frac{\dd{}^2}{\dd{#1}^2}}

\begin{document}

\lhead{Hershal Bhave \quad\tiny{hb6279}}
\rhead{EE351K Fall 2014 Exam 2 Cheat Sheet (Gustavo DeVeciana)}

\begin{multicols}{2}
  \begin{description}
  \item[Properties of RVs] $X$ is continuous; $Y$ is discrete
    $$\int_{-\infty}^{\infty} f_X(x) \dd{x} = 1$$
    $$F_X(x)=\mathbf{P}(X\le x) = \int_{-\infty}^{x}f_X(t)\dd{t}$$
    $$F_Y(y)=\mathbf{P}(Y\le y) = \sum_{k \le x}p_Y(k)$$
  \item[Properties of CDFs] $F_X$ is monotonically nondecreasing,
    approaching $0$ as $x\rightarrow-\infty$ and $1$ as
    $x\rightarrow\infty$
  \item[Normalization of Gaussian CDFs] Remember to normalize before
    doing math operations
    {\footnotesize
      $$\mathbf{P}(X\le x) =
      \mathbf{P}\left(\frac{X-\mu}{\sigma}\le\frac{x-\mu}{\sigma}\right) =
      \mathbf{P}\left(Y\le\frac{x-\mu}{\sigma}\right) =
      \Phi\left(\frac{x-\mu}{\sigma}\right)$$
      $$Y=\frac{X-\mu}{\sigma};
      \quad\mathbf{E}[Y] = \frac{\mathbf{E}[X]-\mu}{\sigma}=0;
      \quad \text{Var}(Y) = \frac{\text{Var}(X)}{\sigma^2} = 1$$
      $$\Phi(-x) = 1 - \Phi(x)\quad \forall x$$
    }
  \item[Discrete Distributions] \hfill
    \begin{description}
    \item[Discrete Uniform] over $[a,b]$:
      \begin{equation*}
        p_X(k) = \left\{
          \begin{aligned}
            & \frac{1}{b-a+1} &&\quad k=a,a+1,\ldots,b \\
            & 0 &&\quad\text{otherwise} \\
          \end{aligned}
        \right.
      \end{equation*}
      $\mathbf{E}[X]=\frac{a+b}{2},\quad
      \text{Var}(X)=\frac{(b-a)(b-a+2)}{12}$
    \item[Bernoulli] with parameter $p$:
      \begin{equation*}
        p_X(k) = \left\{
          \begin{aligned}
            & p &&\quad k=1 \\
            & (1-p) &&\quad k=0
          \end{aligned}
        \right.
      \end{equation*}
      $\mathbf{E}[X] = p,\quad \text{Var}(X)=p(1-p)$
    \item[Binomial] with parameters $p$ and $n$. Number of successes
      in $n$ independent Bernoulli trials
      \begin{equation*}
        p_X(k) = {n \choose k}p^k(1-p)^{n-k},\quad k=0,1,\ldots,n
      \end{equation*}
      $\mathbf{E}[X]=np,\quad\text{Var}(X)=np(1-p)$
    \item[Geometric] with parameter $p$. Number of trials until the
      first success in a sequence of independent Bernoulli trials
      \begin{equation*}
        p_X(k) = (1-p)^{k-1}p,\quad p=1,2,\ldots
      \end{equation*}
      $\mathbf{E}[X]=\frac{1}{p},\quad\text{Var}(X)=\frac{1-p}{p^2}$
    \item[Poisson] with parameter $\lambda$. Approximates the binomial
      PMF when $n$ is large, $p$ is small, and $\lambda = np$
      \begin{equation*}
        p_X(k) = e^{-\lambda\frac{\lambda^k}{k!}},\quad k=0,1,\ldots
      \end{equation*}
      $\mathbf{E}[X]=\lambda,\quad\text{Var}(X)=\lambda$
    \end{description}
  \item[Continuous Distributions] \hfill
    \begin{description}
    \item[Continuous Uniform] over $[a,b]$
      \begin{equation*}
        f_X(x) = \left\{
          \begin{aligned}
            & \frac{1}{b-a} &&\quad x \in [a,b] \\
            & 0 &&\quad \text{otherwise} \\
          \end{aligned}
        \right.
      \end{equation*}
      $\mathbf{E}[X]=\frac{a+b}{2},\quad\text{Var}(X)=\frac{(b-a)^2}{12}$
    \item[Exponential] with parameter $\lambda$
      \begin{equation*}
        f_X(x) = \left\{
          \begin{aligned}
            & \lambda e^{-\lambda x} &&\quad x > 0 \\
            & 0 &&\quad \text{otherwise} \\
          \end{aligned}
        \right.
      \end{equation*}
      $\mathbf{E}[X]=e^{-\lambda x},\quad\text{Var}(X)=\frac{1}{\lambda}$
    \item[Normal/Gaussian] with parameters $\mu_X$ and $\sigma_X^2$
      \begin{equation*}
        \begin{aligned}
          f_X(x) &=
          \frac{1}{\sqrt{2\pi\sigma_X^2}}e^{(-(x-\mu_x)^2)/(2\sigma_X^2)}
          \\
          F_X(x) &= \frac{1}{\sqrt{2\pi\sigma_X^2}} \int_{-\infty}^{x}
          e^{(-(u-\mu)^2)/(2\sigma_X^2)} \dd{u}
        \end{aligned}
      \right.
    \end{equation*}
    $\mathbf{E}[X]=\mu_X,\quad\text{Var}(X)=\sigma_X^2$
  \end{description}
\item[Covariance] $X$ and $Y$ are uncorrelated if 0. Independent
  variables are uncorrelated.
  $$\text{Cov}(X,Y)=E[XY]-E[X]E[Y]$$
\item[Correlation Coefficient]
  $$\rho(X,Y)=\frac{\text{Cov}(X,Y)}{\sqrt{\text{Var}(X)\text{Var}(Y)}}$$
\item[Expectation] $$\mathbf{E}[X] = \int_{-\infty}^{\infty} x f_X(x)
  \dd{x}$$
  $$\mathbf{E}[X] = \sum_x x p_X(x)$$
\item[Variance] $\text{Var}(X) = E[X^2] - E[X]^2$
  $$\text{Var}\left(\sum_{i=1}^{n}X_i\right) =
  E\left(\left[\sum_{i=1}^{n}\tilde{X}_i^2\right]\right)$$
  $$\text{Var}\left(\sum_{i=1}^{n}X_i\right) =
  \left(\sum_{i=1}^{n}\text{Var}(X_i)\right) + \left(\sum_{\{(i,j) |
      i\not= j\}}^{n}\text{Cov}(X_i, X_j)\right)$$
  $$\text{Var}(X_1 + X_2) = \text{Var}(X_1) + \text{Var}(X_2) +
  2\text{Cov}(X_1,X_2)$$
  % \item[Law of Total Variances]
  %   $$\text{Var}(Y) = E[N]\text{Var}(X) + (E[X]^2\text{Var}(N))$$
\item[Conditional Expectation as a Random Variable]
  \begin{equation*}
    \begin{aligned}
      \Psi(y) = E[g(X,Y)|Y=y] &= \int g(x,y) f_{X|Y}(x|y) \dd{x} \\
      &= \sum_{x_i} g(x_i,y) P_{X|Y}(x_i|y)
    \end{aligned}
  \end{equation*}
\item[Conditional PDFs]
  \begin{equation*}
    \begin{aligned}
      f_{X,Y}(x|y) &= f_{X|Y}(x|y)f_Y(y) \\
      &= \frac{f_{X,Y}(x,y)}{f_Y(y)} \\
      f_{X,Y|A}(x,y) &= \frac{f_{X,y}(x,y)}{P(A)}\quad (x,y)\in A \\
    \end{aligned}
  \end{equation*}
\item[Conditional Variance]
  $$ \text{Var}(X|Y) = E[(X-E[X|Y])^2|Y] $$
\end{description}
\end{multicols}
\end{document}